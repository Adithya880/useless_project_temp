# import os
# import random
# from flask import Flask, request, jsonify, render_template
# from werkzeug.utils import secure_filename
# import google.generativeai as genai
# from dotenv import load_dotenv

# # Load API key
# load_dotenv()
# genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# app = Flask(name, template_folder="templates", static_folder="static")
# app.config["UPLOAD_FOLDER"] = os.path.join(app.root_path, "uploads")
# os.makedirs(app.config["UPLOAD_FOLDER"], exist_ok=True)

# # Fallback messages
# FALLBACK_REPLIES = [
#     "ðŸ’” Ghosting level: Expert. They could teach a masterclass.",
#     "ðŸšª Left you on read? Even my fridge light is warmer.",
#     "ðŸ“‰ Love stock down 99%. Sell before bankruptcy.",
#     "ðŸŒ¹ Too sweet? Careful â€” sugar attracts ants ðŸœ.",
#     "ðŸ† Replies instantly? Congrats, youâ€™re their full-time job ðŸš©",
#     "ðŸ¥¶ They text like ice cubes â€” refreshing but cold.",
#     "ðŸª¦ This relationship is running on expired vibes."
# ]

# FALLBACK_INSIGHTS = [
#     "They ignored you? âœ… Respecting your personal space forever.",
#     "They reply in 2 seconds? ðŸš© Future stalker vibes.",
#     "They buy gifts daily? ðŸš© Love bombing alert.",
#     "They liked their exâ€™s post? âœ… Encouraging open networking.",
#     "They never argue? ðŸš© Fake harmony masterclass.",
#     "They said 'k'? âœ… Respecting brevity."
# ]

# def get_flag_by_score(score):
#     """Return danger rating based on score."""
#     if score > 90:
#         return "Red Forest ðŸŒ²"
#     elif score > 70:
#         return "Certified Red Flag ðŸš©"
#     elif score >= 40:
#         return "Yellow Flag âš "
#     elif score >= 20:
#         return "Green Forest ðŸŒ²âœ…"
#     else:
#         return "Green Flag âœ…"

# def analyze_with_gemini(input_text):
#     """Send text to Gemini API and return sarcastic inverted logic prediction."""
#     model = genai.GenerativeModel("models/gemini-1.5-flash")

#     model = genai.GenerativeModel("models/gemini-1.5-flash")

#     prompt = f"""
#     You are a sarcastic breakup predictor with inverted relationship logic.

#     Important:
#     - Base your prediction ONLY on the actual conversation provided.
#     - Do NOT give the same score for different inputs. Use the context
#       to decide whether behaviors are extreme, moderate, or mild.
#     - Positive relationship behaviors should be treated as suspicious or negative.
#     - Negative behaviors should be treated as positive or 'healthy boundaries'.

#     Scoring Rules:
#       - Red Forest ðŸŒ² if score > 90
#       - Red Flag ðŸš© if score 70â€“90
#       - Yellow Flag âš  if score 40â€“70
#       - Green Forest ðŸŒ²âœ… if score 20â€“40
#       - Green Flag âœ… if score 0â€“20

#     Output:
#     - "score" (0â€“100) â†’ based on your judgment of the text.
#     - "reply" â†’ sarcastic, short, with emojis.
#     - "danger_rating" â†’ match exactly to the ranges above.
#     - "flipped_insights" â†’ 3â€“4 bullet points turning normal into suspicious or vice versa.

#     Example Output:
#     {{
#       "score": 95,
#       "reply": "ðŸŒ¹ They bring you flowers daily? ðŸš© Love bombing alert.",
#       "danger_rating": "Red Forest ðŸŒ²",
#       "flipped_insights": [
#         "They never fight with you? ðŸš© Fake harmony.",
#         "They ghosted you? âœ… Respecting your space.",
#         "They reply instantly? ðŸš© Desperation vibes."
#       ]
#     }}

#     Conversation to analyze:
#     \"\"\"{input_text}\"\"\"
#     """

#     try:
#         response = model.generate_content(prompt)
#         return eval(response.text)  # Expect strict JSON
#     except:
#         return {
#             "score": 75,
#             "reply": "ðŸš© Looks like theyâ€™re writing your breakup speech already.",
#             "danger_rating": "Red Flag ðŸš©",
#             "flipped_insights": [
#                 "They text too much? ðŸš© Desperate energy.",
#                 "They ignore you? âœ… Giving you independence.",
#                 "They plan dates ahead? ðŸš© Control freak vibes."
#             ]
#         }
# #
# @app.route("/")
# def home():
#     return render_template("index.html")

# @app.route("/api/predict", methods=["POST"])
# def predict():
#     if "image" in request.files:
#         file = request.files["image"]
#         if file.filename == "":
#             return "âŒ No file selected", 400
#         filename = secure_filename(file.filename)
#         path = os.path.join(app.config["UPLOAD_FOLDER"], filename)
#         file.save(path)
#         fake_text = "They reply instantly every time and keep saying 'you're perfect'."
#         result = analyze_with_gemini(fake_text)
#     else:
#         data = request.get_json()
#         text = data.get("text", "")
#         if not text:
#             return "âŒ No text provided", 400
#         result = analyze_with_gemini(text)

#     # Convert dictionary to human-readable text
#     result_text = (
#         f"Score: {result['score']}\n"
#         f"Danger Rating: {result['danger_rating']}\n"
#         f"Reply: {result['reply']}\n"
#         f"Flipped Insights:\n- " + "\n- ".join(result['flipped_insights'])
#     )

#     return result_text

# if name == "main":
#     app.run(debug=True)




import os
import random
from flask import Flask, request, jsonify, render_template
from werkzeug.utils import secure_filename
import google.generativeai as genai
from dotenv import load_dotenv

# Load API key
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

app = Flask(__name__, template_folder="templates", static_folder="static")
app.config["UPLOAD_FOLDER"] = os.path.join(app.root_path, "uploads")
os.makedirs(app.config["UPLOAD_FOLDER"], exist_ok=True)

FALLBACK_REPLIES = [
    "ðŸ’” Ghosting level: Expert. They could teach a masterclass.",
    "ðŸšª Left you on read? Even my fridge light is warmer.",
    "ðŸ“‰ Love stock down 99%. Sell before bankruptcy.",
    "ðŸŒ¹ Too sweet? Careful â€” sugar attracts ants ðŸœ.",
    "ðŸ† Replies instantly? Congrats, youâ€™re their full-time job ðŸš©",
    "ðŸ¥¶ They text like ice cubes â€” refreshing but cold.",
    "ðŸª¦ This relationship is running on expired vibes."
]

FALLBACK_INSIGHTS = [
    "They ignored you? âœ… Respecting your personal space forever.",
    "They reply in 2 seconds? ðŸš© Future stalker vibes.",
    "They buy gifts daily? ðŸš© Love bombing alert.",
    "They liked their exâ€™s post? âœ… Encouraging open networking.",
    "They never argue? ðŸš© Fake harmony masterclass.",
    "They said 'k'? âœ… Respecting brevity."
]

def get_flag_by_score(score):
    if score > 90:
        return "Red Forest ðŸŒ²"
    elif score > 70:
        return "Certified Red Flag ðŸš©"
    elif score >= 40:
        return "Yellow Flag âš "
    elif score <= 20:
        return "Green Forest ðŸŒ²âœ…"
    else:
        return "Green Flag âœ…"

import json

def analyze_with_gemini(input_text):
    model = genai.GenerativeModel("models/gemini-1.5-flash")

    prompt = f"""
    You are a sarcastic breakup predictor with inverted relationship logic.

    Rules:
    - Predict a breakup score based on the given conversation.
    - Do NOT give the same score for different inputs â€” make it depend on tone and behaviors.
    - Positive behaviors = suspicious/negative.
    - Negative behaviors = positive/healthy boundaries.
    - Return ONLY valid JSON. No explanations.

    JSON format:
    {{
      "score": 0-100,
      "reply": "short sarcastic reply",
      "danger_rating": "Red Forest ðŸŒ² / Red Flag ðŸš© / Yellow Flag âš  / Green Forest ðŸŒ²âœ… / Green Flag âœ…",
      "flipped_insights": ["...", "...", "..."]
    }}

    Conversation:
    \"\"\"{input_text}\"\"\"
    """

    try:
        response = model.generate_content(prompt)
        raw_output = response.candidates[0].content.parts[0].text.strip()

        # Remove triple backticks if Gemini adds them
        if raw_output.startswith("```"):
            raw_output = raw_output.strip("`").strip()
            if raw_output.lower().startswith("json"):
                raw_output = raw_output[4:].strip()

        return json.loads(raw_output)
    except Exception as e:
        print("Gemini parsing error:", e)
        return {
            "score": 75,
            "reply": "ðŸš© Looks like theyâ€™re writing your breakup speech already.",
            "danger_rating": "Red Flag ðŸš©",
            "flipped_insights": [
                "They text too much? ðŸš© Desperate energy.",
                "They ignore you? âœ… Giving you independence.",
                "They plan dates ahead? ðŸš© Control freak vibes."
            ]
        }

@app.route("/")
def home():
    return render_template("index.html")

@app.route("/api/predict", methods=["POST"])
def predict():
    if "image" in request.files:
        file = request.files["image"]
        if file.filename == "":
            return jsonify({"error": "No file selected"}), 400
        filename = secure_filename(file.filename)
        path = os.path.join(app.config["UPLOAD_FOLDER"], filename)
        file.save(path)
        fake_text = "They reply instantly every time and keep saying 'you're perfect'."
        result = analyze_with_gemini(fake_text)
    else:
        data = request.get_json()
        text = data.get("text", "")
        if not text:
            return jsonify({"error": "No text provided"}), 400
        result = analyze_with_gemini(text)
    return jsonify(result)

if __name__ == "__main__":
    app.run(debug=True)